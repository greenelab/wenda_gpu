{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load source data\n",
    "source = pd.read_csv(\"source_data.csv\", sep=\" \")\n",
    "source = source.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "\n",
    "epsilon=1e-6\n",
    "means = np.mean(source, axis=0)\n",
    "stds = np.std(source, axis=0) + epsilon\n",
    "\n",
    "normed = (source - means) / stds\n",
    "source = normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1866, 12980)\n"
     ]
    }
   ],
   "source": [
    "# Transpose data so features/genes are columns and samples are rows as gpytorch expects\n",
    "\n",
    "source = np.transpose(source)\n",
    "print(source.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters and make output dir\n",
    "\n",
    "learning_rate = 1 #Can't remember where this number came from, but I've been hardcoding it for a while\n",
    "# let me know if you think that's a problem source\n",
    "gene_number = 2\n",
    "\n",
    "feature_model_format = 'model_{0:05d}'\n",
    "output_dir = os.path.join(\"gpytorch_feature_models\", feature_model_format.format(gene_number))\n",
    "if os.path.exists(output_dir) is False:\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out feature to predict using all other features\n",
    "\n",
    "y = source[:, gene_number]\n",
    "x = np.delete(source, gene_number, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch objects\n",
    "\n",
    "x_train_tensor = torch.Tensor(x)\n",
    "y_train_tensor = torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and likelihood\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.LinearKernel()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(x_train_tensor, y_train_tensor, likelihood)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put everything on the GPU\n",
    "\n",
    "x_train_tensor = x_train_tensor.cuda()\n",
    "y_train_tensor = y_train_tensor.cuda()\n",
    "model = model.cuda()\n",
    "likelihood = likelihood.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "likelihood.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, likelihood, x, y, learning_rate,\n",
    "                training_iter=40):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    \n",
    "    for i in range(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = -mll(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model, likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ariel/miniconda3/envs/wenda_gpu/lib/python3.7/site-packages/gpytorch/utils/linear_cg.py:278: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /tmp/pip-req-build-pp_v77a7/aten/src/ATen/native/Resize.cpp:23.)\n",
      "  curr_conjugate_vec,\n"
     ]
    }
   ],
   "source": [
    "model, likelihood = train_model(model, likelihood, x_train_tensor,\n",
    "                                         y_train_tensor, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('likelihood.noise_covar.raw_noise',\n",
       "              tensor([-8.9069], device='cuda:0')),\n",
       "             ('likelihood.noise_covar.raw_noise_constraint.lower_bound',\n",
       "              tensor(1.0000e-04, device='cuda:0')),\n",
       "             ('likelihood.noise_covar.raw_noise_constraint.upper_bound',\n",
       "              tensor(inf, device='cuda:0')),\n",
       "             ('mean_module.constant', tensor([-0.4300], device='cuda:0')),\n",
       "             ('covar_module.raw_variance',\n",
       "              tensor([[-10.9865]], device='cuda:0')),\n",
       "             ('covar_module.raw_variance_constraint.lower_bound',\n",
       "              tensor(0., device='cuda:0')),\n",
       "             ('covar_module.raw_variance_constraint.upper_bound',\n",
       "              tensor(inf, device='cuda:0'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save state dict\n",
    "\n",
    "torch.save(model.state_dict(),os.path.join(output_dir, \"state_dict.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target data, confidence scores are calculated based on\n",
    "# how well the GP models predict on the target distribution\n",
    "\n",
    "target = pd.read_csv(\"target_data.csv\", sep = \" \")\n",
    "target = target.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "\n",
    "epsilon=1e-6\n",
    "means = np.mean(target, axis=0)\n",
    "stds = np.std(target, axis=0) + epsilon\n",
    "\n",
    "normed = (target - means) / stds\n",
    "target = normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 12980)\n"
     ]
    }
   ],
   "source": [
    "# Transpose data so features/genes are columns and samples are rows as gpytorch expects\n",
    "\n",
    "target = np.transpose(target)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out gene to be predicted\n",
    "\n",
    "y_test = target[:, gene_number]\n",
    "y_test_tensor = torch.Tensor(y_test).cuda()\n",
    "x_test = np.delete(target, gene_number, 1)\n",
    "x_test_tensor = torch.Tensor(x_test).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get confidence score based on CDF of true target value on GP model\n",
    "def getConfidence(model, x, y):\n",
    "    with gpytorch.settings.fast_pred_var():\n",
    "        f_preds = model(x)\n",
    "    mu = f_preds.mean\n",
    "    sigma_sq = f_preds.variance\n",
    "    sigma_sq = torch.sqrt(sigma_sq)\n",
    "    res_normed = (y - mu) / sigma_sq\n",
    "    res_normed = res_normed.cpu().detach().numpy()\n",
    "    confidences = (1 - abs(norm.cdf(res_normed) - norm.cdf(-res_normed)))\n",
    "    mu = mu.cpu().detach().numpy()\n",
    "    sigma_sq = sigma_sq.cpu().detach().numpy()\n",
    "    return mu, sigma_sq, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out confidence scores and predicted means and variances on target data\n",
    "mean, var, conf = getConfidence(model, x_test_tensor, y_test_tensor)\n",
    "conf_file = os.path.join(output_dir, \"confidences.txt\")\n",
    "np.savetxt(conf_file, conf, fmt='%.10f')\n",
    "mean_file = os.path.join(output_dir, \"predicted_means.txt\")\n",
    "np.savetxt(mean_file, mean, fmt='%.5f')\n",
    "var_file = os.path.join(output_dir, \"predicted_variances.txt\")\n",
    "np.savetxt(var_file, var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
